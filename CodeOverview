Overview:
This code works by generating massless test particles in random but structured locations following 
user input of parameters required for calculation. Then after clearing the folders form any previous
runs of the code the variables are fed into a (heavily) modified amalgamation of the Orbit Plot
(https://rebound.readthedocs.io/en/latest/ipython_examples/OrbitPlot/) and 
Test Particles(https://rebound.readthedocs.io/en/latest/ipython_examples/Testparticles/) examples 
provided in the Rebound Documentation(https://rebound.readthedocs.io/en/latest/). 
Rebound is an open source N-body integrator python package and is the backbone for this entire project. 
Once Rebound outputs the file of position and velocity vectors for each particle and the data has been 
extracted from the binary file the analysis can begin. Our first step is to use our newly extracted 
data to calculate the luminosity of each individual particle. Once each particle has an assigned 
luminosity as well as a few other parameters it is assigned a velocity bin based on its line of sight 
velocity to the observer. The total luminosity in each bin is then plotted to output a spectrum.

Note: This code has been modified to make it easier to read. Do not copy and paste. It will not work.


# User Set Parameters --------------------------------------------------------------
'''Code units are in cgs'''


BHM = 6.5e8                    # Black hole mass in solar masses
KVZ = 3000e5                   # Kick velocity in z-direction cm / s
KVX = 0			                   # Kick in x-direction
KVY = 0			                   # Kick in y-direction
RS = 42                        # Set seed for repeatability

N_testparticle = 10000         # Number of test particles
^^^
Note: This is the one of the main factors in determining how fast the code will run (the other being your
computer specs). If you want quick simulations for producing animations I recommend running with 2,500
particles or less. If you want more detailed spectra then a minimum of 5,000 particles should suffice.


Nimg = 500                     # Number of frames you want the simulation to generate
LAGN = 10**45                  # Bolometric luminosity of the AGN in ergs/s. Used for dust sublimation radius
Y = 20                         # Size scaled to broadline region. Determines the size of the initial area the particles can use
Qh = 2.6e55                    # Ionizing photon luminosity photons/s
Tsub = 1500                    # Dust sublimation temperature
Cf = 1                         # Covering fraction
Eratio = 1                     # Eddington ratio
sigma = 1                      # Angular width
p = 1                          # Cloud distribution power law
c =  2.998e10                  # Conversion for speed of light cm/s


# Calculated parameters--------------------------------------------------------

BHMg = BHM * 1.989e+33              # Solar mass to g
SwR = ((2*BHMg*(6.67e-8))/(c**2))   # Schwarzschild Radius (cm)
Rd = (0.4*((((LAGN)/(10**45))**0.5)*((1500/Tsub)**2.6)))* 3.086e+18 # Dust sublimation radius


# Constants--------------------------------------------------------------------

alphaeff = 1.1e-13              # Effective recombination coefficient for Halpha cm^3*s^-1
alphaB = 2.6e-13                # Recombination coefficient for hydrogen cm^3*s^-1
Qh = 2.6e55                     # Ionizing photon luminosity photons*s^-1
h = 6.62607015e-27 
EffRecomb = 1.1e13              # cm^3 s^−1
nu = (c)/(656e-7)		# Wavelength for Halpha


# Simulation ------------------------------------------------------------------

Set up the particles in the simulation. Particles are added by default in
Jacobi coordinates (center-of-mass frame)

sim = rebound.Simulation()    # Initialize the simulation
sim.units = ('s', 'cm', 'g')  # Set simulation units
sim.ri_ias15.min_dt = 10000   # Set minimum timestep length in seconds
sim.add(m = BHMg)             # Add the central particle (SMBH)
primary=sim.particles[0]      # Primary particle for Rebound
np.random.seed(RS)            # Random seed for test cases


# Set up initial distribution of test particles --------------------------------

a_initial = np.linspace(Rd/Y, Rd, N_testparticle) # Initial range of semi major axis to distribute particles

Range determined by the dust sublimation radius and the size scaled to BLR

for a in a_initial:
    sim.add(a=a,
            inc = np.random.uniform(low = -0.1, high = 0.1), # Inclination - uniformly random
            Omega = np.random.uniform(high = np.pi),         # Longitude of ascending node - uniformly random
            f=np.random.rand()*2.*np.pi)                     # Mass set to 0 by default. Random true anomaly - pseudo-random from NumPy
    
        
# Integration -----------------------------------------------------------------

Loops for N timesteps provided by the user in the initial step

for i in range(Nimg):
    if i == 0: 		Print the base simulation before any modification

        coords = np.zeros((sim.N, 6))
        sim.serialize_particle_data(xyzvxvyvz=coords)
        fig, ([ax1, ax2], [ax3, ax4]) = plt.subplots(2,2, figsize = (12,10), dpi = 200)

        # XY graph

        # YZ graph

        # XZ graph

        # Empty space

        sim.step()
    
    else:		Add velocity kick

        sim.particles[0].vz = KVZ    # Changing the z velocity of the central particle
        sim.particles[0].vx = KVX
        sim.particles[0].vy = KVY      
        sim.step()                   # Move forward one timestep
        coords = np.zeros((sim.N, 6))
        sim.serialize_particle_data(xyzvxvyvz=coords)
        fig, ([ax1, ax2], [ax3, ax4]) = plt.subplots(2,2, figsize = (12,10), dpi = 200)

        # XY graph

        # YZ graph
       
        # XZ graph
       
        # Empty space
        
    if i % 10 == 0:        Saves every 10th timestep to an image for the sake of file size
        plt.savefig("path/AnimationFolder/image_%s.jpg" % i)
        
	Saving each plot to a file with it's own name to be created into a gif https://ezgif.com/maker  
    
    sim.save_to_file("path/RawData/archive.bin") 


#%% Begin Data Extraction------------------------------------------------------


# Initialize Simulationarchive simulation--------------------------------------

Function from Rebound used to visualize simulations by reading the binary file output

sa = rebound.Simulationarchive("path/RawData/archive.bin")

N_archives = len(sa)


# Initialize empty data arrays-------------------------------------------------

Empty arrays that match the size of our data

save_times = np.zeros(N_archives)
# 2 dimensional array of size N saves and M particles
particles_x = np.zeros((N_archives, (N_testparticle + 1))) 
particles_y = np.zeros((N_archives, (N_testparticle + 1)))
particles_z = np.zeros((N_archives, (N_testparticle + 1)))
particles_vx = np.zeros((N_archives, (N_testparticle + 1)))
particles_vy = np.zeros((N_archives, (N_testparticle + 1)))
particles_vz = np.zeros((N_archives, (N_testparticle + 1)))


# Loop through and pull out all of the values of interest------------------

Pulls data from simulationarchive

for i, sim in enumerate(sa):
    save_times[i] = sim.t
    for j in range(1, sim.N):
        particles_x[i, j] = sim.particles[j].x
        particles_y[i, j] = sim.particles[j].y
        particles_z[i, j] = sim.particles[j].z
        particles_vx[i, j] = sim.particles[j].vx
        particles_vy[i, j] = sim.particles[j].vy
        particles_vz[i, j] = sim.particles[j].vz 


# Save each individual parameter to its own CSV--------------------------------

x_data = np.concatenate([[save_times], particles_x.T])
np.savetxt('path/RawData/simXdata.csv',
           x_data, delimiter=', ')

vx_data = np.concatenate([[save_times], particles_vx.T])
np.savetxt('path/RawData/simVXdata.csv', 
           vx_data, delimiter=', ')

y_data = np.concatenate([[save_times], particles_y.T])
np.savetxt('path/RawData/simYdata.csv', 
           y_data, delimiter=', ')

vy_data = np.concatenate([[save_times], particles_vy.T])
np.savetxt('path/RawData/simVYdata.csv', 
           vy_data, delimiter=', ')

z_data = np.concatenate([[save_times], particles_z.T])
np.savetxt('path/RawData/simZdata.csv', 
           z_data, delimiter=', ')

vz_data = np.concatenate([[save_times], particles_vz.T])
np.savetxt('path/RawData/simVZdata.csv', 
           vz_data, delimiter=', ')


# Split CSVs into individual timestep CSVs-------------------------------------

Divides each parameter csv into a new csv containing all data for a single timestep

var_list = ['X', 'Y', 'Z', 'Vx', 'Vy', 'Vz']     # Column titles
t_step = np.arange(len(sa))                      # Number of files it needs to make - Matches with # of images
df_list = [x, y, z, vx, vy, vz]                  # List of dataframes
t_dict = {}
for i, t in enumerate(t_step):                   # Loop through each column in each parameter csv
    temp_df = pd.DataFrame()
    for j, df in enumerate(df_list):
        var = var_list[j]
        temp_df[var] = df.iloc[0:, i]
    temp_df.to_csv(f'path/TimestepData/t{t}.csv')
    

#%% Luminosity Calculations------------------------------------------------------

ObsInc = 0 # Inclination of observer 90 degrees for full disk 0 degrees for edge on view Range: +/- 90 degrees
plt.ion() 

timestep = 00    # What timestep to use for calculations
sim = sa[timestep]


# Cloud radius-----------------------------------------------------------------

Rcl = []
for i in range(N_testparticle):
    radius = np.random.uniform(low = 10**12, high = 10**14) # cm
    Rcl.append(radius)

Gives particle a random radius from the specified range. Uniform distribution


# Gas and column density-------------------------------------------------------

nr = np.linspace(10**8, 10**9, N_testparticle) # Specify range for column density
for i in nr:
    nr = nr
    Nc = nr* Rcl


# Cloud radial distance from center and Keplerian velocity---------------------

Luminosity depends on the particle’s distance to the SMBH which is the source of the ionizing radiation.
If the cloud is partially ionized, its luminosity is proportional to the ionizing photon flux, F(r)
If the cloud is fully ionized its luminosity is proportional to the mass of the cloud

Vkep = []
dist = []
r = []
for i in range(N_testparticle+1):
    r = (np.sqrt(((sim.particles[0].x-sim.particles[i].x)**2)+((sim.particles[0].y-sim.particles[i].y)**2)+((sim.particles[0].z-sim.particles[i].z)**2)))
    dist.append(r)
    with np.errstate(divide='ignore'):
        kep = np.sqrt((6.67259e-8*BHMg)/r)
        Vkep.append(kep)
        

# Ionization state of the cloud------------------------------------------------

Urt = []
for i in range(N_testparticle):
    U = (Qh/(4*np.pi*((dist[i])**2)*c*nr[i]))
    Urt.append(U)
   
Urt = np.array(Urt)


# Radiation vs Matter-bounded cloud--------------------------------------------

Lcl1 = np.zeros(N_testparticle) 
Lcl2 = np.zeros(N_testparticle) 
dc = np.zeros(N_testparticle)
ds = np.zeros(N_testparticle)

for i in range(N_testparticle):
    dc[i] = Rcl[i]
    ds[i] = ((c*Urt[i])/(alphaB*nr[i]))


# Individual cloud luminosity--------------------------------------------------

The actual calculation for the luminosity

for i in range(N_testparticle):
    if ds[i]<dc[i]:
        Lcl1[i] = nr[i]**2*(alphaeff)*h*(nu)*np.pi*(Rcl[i]**2)*ds[i] # For ds<dc Radiation bounded
    else:
        Lcl2[i] = nr[i]**2*(alphaeff)*h*(nu)*np.pi*(Rcl[i]**2)*Rcl[i] # Matter bounded

print('Total Cloud luminosity for timestep', timestep, ':', sum(Lcl1+Lcl2))


# Simulated Spectra------------------------------------------------------------


# Line of sight velocity-------------------------------------------------------

if ObsInc == 90:
    LoS = data['Vz']

if ObsInc == 0:
    LoS = data['Vy']

For any observer angle that is not 0 or +/-90 degrees a rotational transformation is applied


def rotate_x(matrix, angle): # Rotation about the x-axis by inclination of observer

    rotation_matrix = np.array([
        [1, 0, 0],
        [0, np.cos(angle), -np.sin(angle)],
        [0, np.sin(angle), np.cos(angle)]
    ])

    return np.dot(rotation_matrix, matrix)

theta = ObsInc*(np.pi/180)

if 0 < ObsInc < 90:
    angle = theta
    rotatedLoS = []
    coordinates = []
    rotatedKick = []
    for i in range(N_testparticle+1): # Particle rotation
        posmatrix = np.array([sim.particles[i].x, sim.particles[i].y, sim.particles[i].z])
        velmatrix = np.array([sim.particles[i].vx, sim.particles[i].vy, sim.particles[i].vz])
        rotated_position = rotate_x(posmatrix, angle)
        rotated_velocity = rotate_x(velmatrix,angle)
        rotatedLoS.append(rotated_velocity)
        coordinates.append(rotated_position)
    for i in range(1): # Kick rotation
        kickmatrix = np.array([KVX,KVY,KVZ])
        rotated_kick = rotate_x(kickmatrix,angle)
    LoS = [ x[2] for x in rotatedLoS]
    LoS = np.array(LoS) 


# Determine bin range----------------------------------------------------------

Establish velocity bins to set up graph of spectra

numbin = 150

if abs(LoS.max())> abs(LoS.min()):
    binsmax = LoS.max() 
    binsmin = -LoS.max()
if abs(LoS.max())< abs(LoS.min()):
    binsmax = -LoS.min()
    binsmin = LoS.min()

bin_width = (binsmax - binsmin) / numbin


# Total Luminosity in each bin-------------------------------------------------

zeros = pd.DataFrame([0])
Lvals = pd.concat([Lcl1,Lcl2], axis = 1)
Lval = Lvals['Lcl1'] + Lvals['Lcl2']
Lval = pd.concat([zeros, Lval])

LoS = np.array(LoS)
Lval = np.ravel(Lval)

Lsum, sortedV, Bin = stats.binned_statistic_dd(LoS, Lval, statistic='sum', bins = numbin)    

# Plot-------------------------------------------------------------------------

fig, ax = plt.subplots(figsize=(12, 8), dpi = 200)

ax.plot(Lsum)
ax.set(title = 'Simulated Spectra\nTime Passed:'+str(f"{sim.t:.3e}"+' seconds'),
       ylabel = 'Total Luminosity (ergs/s)',
       xlabel = 'Velocity Bins '+str(numbin)+' (velocity in cm/s)')

xticks = np.arange(0, numbin+1, numbin/5)
index = xticks.astype(int).tolist()
sortedV = np.array(sortedV)
sortedV = np.transpose(sortedV)
labels = np.round(sortedV[index],decimals = 3)

ax.set_xticks(xticks, labels = labels)
